# Architecture Overview - Kolegium AI Writing Flow

## ğŸ—ï¸ System Architecture

### Container Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Compose Stack                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   AI Writing    â”‚  â”‚    ChromaDB     â”‚  â”‚    Redis    â”‚â”‚
â”‚  â”‚     Flow        â”‚  â”‚  Vector Store   â”‚  â”‚    Cache    â”‚â”‚
â”‚  â”‚   (Port 8003)   â”‚  â”‚  (Port 8001)    â”‚  â”‚ (Port 6380) â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â”‚                    â”‚                   â”‚        â”‚
â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                               â”‚                             â”‚
â”‚                        â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚                        â”‚   Shared     â”‚                     â”‚
â”‚                        â”‚   Network    â”‚                     â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Data Flow - TRUE Agentic RAG

### Content Generation Flow
```
User Request
    â†“
generate_draft()
    â†“
analyze_with_iterations() â† TRUE Agentic RAG
    â†“
OpenAI Agent (GPT-4)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Autonomous Decision Loop       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ "I need LinkedIn rules"     â”‚â”‚
â”‚  â”‚         â†“                   â”‚â”‚
â”‚  â”‚ query_style_guide()         â”‚â”‚
â”‚  â”‚         â†“                   â”‚â”‚
â”‚  â”‚ "Now I need hook examples"  â”‚â”‚
â”‚  â”‚         â†“                   â”‚â”‚
â”‚  â”‚ query_style_guide()         â”‚â”‚
â”‚  â”‚         â†“                   â”‚â”‚
â”‚  â”‚ (3-5 iterations)           â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
CrewAI Writer Agent
    â†“
Generated Content (Unique Each Time)
```

## ğŸ§  AI Agent Architecture

### 1. OpenAI Function Calling Agent (Agentic RAG)
- **Role**: Autonomous style guide researcher
- **Model**: GPT-4-turbo
- **Function**: `search_style_guide`
- **Behavior**: Decides what to search, when to search, when to stop
- **Iterations**: 3-5 autonomous queries

### 2. CrewAI Writer Agent
- **Role**: Content creator
- **Model**: GPT-4 via LangChain
- **Input**: Style guide discoveries from OpenAI agent
- **Output**: Platform-optimized content

### 3. Style Guide Expert (Deprecated)
- Previously used for "fake" agentic RAG
- Replaced by OpenAI Function Calling

## ğŸ’¾ Data Storage

### ChromaDB Vector Store
- **Collection**: `vector_wave_style_guide`
- **Documents**: 180 style guide rules
- **Source**: Markdown files in `/styleguides`
- **Embedding**: all-MiniLM-L6-v2
- **Query**: Semantic similarity search

### Redis Cache
- **Analysis Cache**: 5-minute TTL
- **Key Format**: `analysis:{folder_name}`
- **Preload Cache**: Content folders on startup
- **Batch Results**: Custom ideas analysis

## ğŸ”Œ API Endpoints

### Core Endpoints
1. `POST /api/generate-draft` - Main content generation with Agentic RAG
2. `POST /api/style-guide/analyze-iterative` - Direct iterative analysis
3. `POST /api/analyze-custom-ideas-stream` - SSE batch analysis
4. `POST /api/chat` - AI Assistant for draft editing

### Supporting Endpoints
- `/api/style-guide/seed` - Load rules from files
- `/api/style-guide/check` - Simple style check
- `/api/analyze-potential` - Quick content scoring
- `/health` - Container health check

## ğŸš€ Key Design Decisions

### 1. TRUE Agentic RAG
- **Problem**: Previous "agentic" was actually naive with hardcoded queries
- **Solution**: OpenAI Function Calling with autonomous agent loop
- **Result**: Each generation unique, agent decides everything

### 2. Container-First Architecture
- **Problem**: Complex multi-service dependencies
- **Solution**: Docker Compose with health checks
- **Result**: Single command deployment

### 3. Streaming for Long Operations
- **Problem**: 20-50s generation times
- **Solution**: SSE for real-time progress
- **Result**: Better UX with progress tracking

### 4. Smart Caching Strategy
- **Problem**: Expensive AI operations
- **Solution**: Multi-layer cache (preload â†’ Redis â†’ generate)
- **Result**: Instant responses for repeated queries

## ğŸ“Š Performance Characteristics

### Response Times
- **generate-draft**: 20-50s (with Agentic RAG)
- **analyze-potential**: 1ms (cached/calculated)
- **style-guide/analyze-iterative**: 15-30s
- **chat**: 5-15s (depending on operation)

### Resource Usage
- **Memory**: ~2GB (mainly ChromaDB embeddings)
- **CPU**: Spikes during generation
- **Network**: OpenAI API calls (3-8 per generation)

## ğŸ” Security Considerations

1. **API Keys**: Environment variables only
2. **Network**: Internal Docker network
3. **Ports**: Minimal exposure (8003 for API)
4. **Data**: No PII stored, only content

## ğŸ¯ Future Optimizations

1. **Parallel Searches**: Agent could search multiple queries simultaneously
2. **Search Caching**: Cache individual style guide searches
3. **Model Selection**: Use smaller models for simple queries
4. **Batch Generation**: Process multiple drafts in parallel