# üõ°Ô∏è Enhanced Mock Detection Strategy
**Vector Wave Zero-Hardcoded-Rules Enforcement System**

## üìä Executive Summary

**Objective**: Prevent introduction of hardcoded rules during Vector Wave migration through automated detection, validation, and enforcement mechanisms.

**Challenge**: During migration from 355+ hardcoded rules to ChromaDB-centric architecture, there's high risk of developers accidentally introducing new hardcoded rules or maintaining existing ones.

**Solution**: Multi-layer detection strategy with automated tools, pre-commit hooks, and continuous validation.

---

## üéØ Strategy Overview

### Detection Layers
```yaml
detection_layers:
  layer_1_development:
    tools: ["IDE extensions", "real-time linting", "developer feedback"]
    trigger: "During code writing"
    response_time: "< 1 second"
    
  layer_2_commit:
    tools: ["pre-commit hooks", "git hooks", "automated scanning"]
    trigger: "Before commit"
    response_time: "< 10 seconds"
    
  layer_3_ci_cd:
    tools: ["pipeline validation", "automated testing", "deployment gates"]
    trigger: "CI/CD pipeline"
    response_time: "< 5 minutes"
    
  layer_4_runtime:
    tools: ["health checks", "cache validation", "API monitoring"]
    trigger: "Production runtime"
    response_time: "Real-time monitoring"
```

### Success Criteria
‚úÖ **Zero False Positives**: Detection accuracy > 99%  
‚úÖ **Complete Coverage**: Scan all code files, configs, and data  
‚úÖ **Fast Execution**: Detection completes in < 30 seconds  
‚úÖ **Developer Friendly**: Clear error messages with fix suggestions  
‚úÖ **CI/CD Integration**: Automated pipeline gates  

---

## üîç 1. HARDCODED RULE DETECTION PATTERNS

### 1.1 Primary Detection Signatures

```python
# Hardcoded Rule Detection Patterns
HARDCODED_PATTERNS = {
    "forbidden_phrases": {
        "patterns": [
            r"forbidden_phrases\s*=\s*\[",
            r"FORBIDDEN_PHRASES\s*=",
            r"banned_words\s*=\s*\[",
            r"blacklisted_terms\s*=",
            r"prohibited_content\s*="
        ],
        "severity": "CRITICAL",
        "message": "Hardcoded forbidden phrases detected. Use ChromaDB style_editorial_rules collection."
    },
    
    "validation_rules": {
        "patterns": [
            r"validation_rules\s*=\s*\[",
            r"VALIDATION_RULES\s*=",
            r"content_rules\s*=\s*\[",
            r"editorial_rules\s*=",
            r"style_rules\s*=\s*\["
        ],
        "severity": "CRITICAL", 
        "message": "Hardcoded validation rules detected. Use Editorial Service API endpoints."
    },
    
    "platform_constraints": {
        "patterns": [
            r"character_limits\s*=\s*{",
            r"CHARACTER_LIMITS\s*=",
            r"platform_rules\s*=\s*{",
            r"posting_limits\s*=",
            r"media_constraints\s*="
        ],
        "severity": "HIGH",
        "message": "Hardcoded platform constraints. Use ChromaDB publication_platform_rules collection."
    },
    
    "scheduling_rules": {
        "patterns": [
            r"optimal_times\s*=\s*\[",
            r"OPTIMAL_POSTING_TIMES\s*=",
            r"best_times\s*=",
            r"posting_schedule\s*=",
            r"time_constraints\s*="
        ],
        "severity": "HIGH",
        "message": "Hardcoded scheduling rules. Use ChromaDB scheduling_optimization collection."
    },
    
    "fallback_data": {
        "patterns": [
            r"fallback_rules\s*=",
            r"default_rules\s*=",
            r"backup_rules\s*=",
            r"emergency_rules\s*=",
            r"if.*rules.*empty.*:",
            r"if.*not.*rules.*:"
        ],
        "severity": "MEDIUM",
        "message": "Fallback/default rules detected. Implement proper circuit breaker with ChromaDB."
    },
    
    "mock_data_in_production": {
        "patterns": [
            r"mock_rules\s*=",
            r"test_rules\s*=",
            r"sample_rules\s*=",
            r"dummy_rules\s*=",
            r"placeholder_rules\s*="
        ],
        "severity": "CRITICAL",
        "message": "Mock data in production code. Remove or move to test files."
    }
}
```

### 1.2 Context-Aware Detection

```python
# Context-Sensitive Pattern Detection
CONTEXT_PATTERNS = {
    "array_assignments": {
        "pattern": r"(\w+)\s*=\s*\[\s*(['\"][^'\"]*['\"],?\s*){3,}\]",
        "context_check": lambda match: (
            len(match.group(2).split(',')) > 5 and
            any(keyword in match.group(1).lower() for keyword in 
                ['rule', 'phrase', 'word', 'term', 'constraint', 'limit'])
        ),
        "severity": "HIGH",
        "message": "Large array assignment suggests hardcoded rules."
    },
    
    "dictionary_rules": {
        "pattern": r"(\w+)\s*=\s*{\s*['\"].*['\"]\s*:\s*.*}",
        "context_check": lambda match: (
            'rule' in match.group(1).lower() or 
            'constraint' in match.group(1).lower() or
            'limit' in match.group(1).lower()
        ),
        "severity": "MEDIUM",
        "message": "Dictionary-based configuration suggests hardcoded rules."
    },
    
    "inline_validation": {
        "pattern": r"if\s+.*in\s+\[(['\"][^'\"]*['\"],?\s*){3,}\]",
        "severity": "HIGH", 
        "message": "Inline array validation suggests hardcoded rules."
    }
}
```

### 1.3 File-Type Specific Detection

```yaml
# File-Type Detection Rules
file_type_rules:
  python_files:
    extensions: [".py"]
    additional_patterns:
      - "STYLEGUIDE = {"
      - "EDITORIAL_CONFIG = ["
      - "PLATFORM_RULES = {"
    ignore_patterns:
      - "test_*.py"
      - "*_test.py"
      - "conftest.py"
      
  javascript_files:
    extensions: [".js", ".ts"]
    additional_patterns:
      - "const RULES = ["
      - "const CONSTRAINTS = {"
      - "export const VALIDATION"
    ignore_patterns:
      - "*.test.js"
      - "*.spec.js"
      - "test/**"
      
  configuration_files:
    extensions: [".yaml", ".yml", ".json"]
    additional_patterns:
      - '"rules": ['
      - '"constraints": {'
      - '"validation": {'
    ignore_patterns:
      - "test-config.*"
      - "mock-config.*"
      
  markdown_files:
    extensions: [".md"]
    additional_patterns:
      - "```python\n.*rules.*=.*\["
      - "```javascript\n.*RULES.*="
    ignore_patterns:
      - "README.md"
      - "docs/**"
```

---

## üîß 2. AUTOMATED DETECTION TOOLS

### 2.1 CLI Detection Tool

```python
#!/usr/bin/env python3
"""
Vector Wave Hardcoded Rule Detector
Usage: python hardcoded_detector.py [path] [--fix] [--strict]
"""

import re
import os
import sys
import json
import argparse
from pathlib import Path
from typing import List, Dict, Tuple
from dataclasses import dataclass

@dataclass
class DetectionResult:
    file_path: str
    line_number: int
    pattern_name: str
    severity: str
    message: str
    suggested_fix: str
    context_lines: List[str]

class HardcodedRuleDetector:
    def __init__(self, config_path: str = None):
        self.patterns = HARDCODED_PATTERNS  # From above
        self.context_patterns = CONTEXT_PATTERNS  # From above
        self.results = []
        self.stats = {"files_scanned": 0, "violations_found": 0}
    
    def scan_directory(self, directory: Path, recursive: bool = True) -> List[DetectionResult]:
        """Scan directory for hardcoded rules"""
        
        results = []
        
        for file_path in directory.rglob("*" if recursive else "*"):
            if file_path.is_file() and self._should_scan_file(file_path):
                self.stats["files_scanned"] += 1
                file_results = self._scan_file(file_path)
                results.extend(file_results)
                self.stats["violations_found"] += len(file_results)
        
        return results
    
    def _should_scan_file(self, file_path: Path) -> bool:
        """Determine if file should be scanned"""
        
        # Skip test files, node_modules, .git, etc.
        skip_patterns = [
            r"test.*\.py$",
            r".*_test\.py$", 
            r"conftest\.py$",
            r"node_modules/",
            r"\.git/",
            r"__pycache__/",
            r"\.pytest_cache/",
            r"venv/",
            r"\.env"
        ]
        
        file_str = str(file_path)
        return not any(re.search(pattern, file_str) for pattern in skip_patterns)
    
    def _scan_file(self, file_path: Path) -> List[DetectionResult]:
        """Scan individual file for hardcoded rules"""
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
        except (UnicodeDecodeError, IOError):
            return []  # Skip binary or unreadable files
        
        results = []
        
        # Scan each line for patterns
        for line_num, line in enumerate(lines, 1):
            # Primary pattern detection
            for pattern_name, pattern_info in self.patterns.items():
                for pattern in pattern_info["patterns"]:
                    if re.search(pattern, line, re.IGNORECASE):
                        
                        suggested_fix = self._generate_fix_suggestion(pattern_name, line)
                        context = self._get_context_lines(lines, line_num)
                        
                        result = DetectionResult(
                            file_path=str(file_path),
                            line_number=line_num,
                            pattern_name=pattern_name,
                            severity=pattern_info["severity"],
                            message=pattern_info["message"],
                            suggested_fix=suggested_fix,
                            context_lines=context
                        )
                        results.append(result)
            
            # Context-aware pattern detection
            for pattern_name, pattern_info in self.context_patterns.items():
                match = re.search(pattern_info["pattern"], line)
                if match and pattern_info.get("context_check", lambda x: True)(match):
                    
                    result = DetectionResult(
                        file_path=str(file_path),
                        line_number=line_num,
                        pattern_name=f"context_{pattern_name}",
                        severity=pattern_info["severity"], 
                        message=pattern_info["message"],
                        suggested_fix=self._generate_context_fix(pattern_name, line),
                        context_lines=self._get_context_lines(lines, line_num)
                    )
                    results.append(result)
        
        return results
    
    def _generate_fix_suggestion(self, pattern_name: str, line: str) -> str:
        """Generate fix suggestion based on detected pattern"""
        
        fix_suggestions = {
            "forbidden_phrases": "Replace with: await editorial_service.get_style_rules(query='forbidden_phrases')",
            "validation_rules": "Replace with: await editorial_service.validate_comprehensive(content, platform)",
            "platform_constraints": "Replace with: await editorial_service.get_platform_rules(platform)",
            "scheduling_rules": "Replace with: await editorial_service.get_scheduling_rules(platform)",
            "fallback_data": "Implement circuit breaker: if chromadb_unavailable: return graceful_degradation()",
            "mock_data_in_production": "Move to test file or replace with ChromaDB query"
        }
        
        return fix_suggestions.get(pattern_name, "Replace with ChromaDB query via Editorial Service API")
    
    def _generate_context_fix(self, pattern_name: str, line: str) -> str:
        """Generate context-specific fix suggestion"""
        
        return f"Refactor large data structure to ChromaDB collection. See target-version/CHROMADB_SCHEMA_SPECIFICATION.md"
    
    def _get_context_lines(self, lines: List[str], line_num: int, context: int = 2) -> List[str]:
        """Get surrounding lines for context"""
        
        start = max(0, line_num - context - 1)
        end = min(len(lines), line_num + context)
        return lines[start:end]
    
    def generate_report(self, results: List[DetectionResult], format: str = "console") -> str:
        """Generate detection report"""
        
        if format == "console":
            return self._generate_console_report(results)
        elif format == "json":
            return self._generate_json_report(results)
        elif format == "markdown":
            return self._generate_markdown_report(results)
        else:
            raise ValueError(f"Unsupported format: {format}")
    
    def _generate_console_report(self, results: List[DetectionResult]) -> str:
        """Generate console-friendly report"""
        
        if not results:
            return "‚úÖ No hardcoded rules detected!"
        
        report = []
        report.append(f"üö® HARDCODED RULES DETECTED: {len(results)} violations")
        report.append("=" * 60)
        
        # Group by severity
        by_severity = {}
        for result in results:
            by_severity.setdefault(result.severity, []).append(result)
        
        for severity in ["CRITICAL", "HIGH", "MEDIUM", "LOW"]:
            if severity in by_severity:
                report.append(f"\nüî¥ {severity} SEVERITY ({len(by_severity[severity])} issues)")
                report.append("-" * 40)
                
                for result in by_severity[severity]:
                    report.append(f"üìÑ {result.file_path}:{result.line_number}")
                    report.append(f"   Issue: {result.message}")
                    report.append(f"   Fix: {result.suggested_fix}")
                    report.append("")
        
        # Summary statistics
        report.append("üìä SCAN STATISTICS")
        report.append(f"   Files scanned: {self.stats['files_scanned']}")
        report.append(f"   Violations found: {self.stats['violations_found']}")
        
        return "\n".join(report)
    
    def _generate_json_report(self, results: List[DetectionResult]) -> str:
        """Generate JSON report for CI/CD integration"""
        
        report_data = {
            "summary": {
                "total_violations": len(results),
                "files_scanned": self.stats["files_scanned"],
                "severity_breakdown": {}
            },
            "violations": []
        }
        
        # Count by severity
        for result in results:
            severity = result.severity
            report_data["summary"]["severity_breakdown"][severity] = \
                report_data["summary"]["severity_breakdown"].get(severity, 0) + 1
            
            report_data["violations"].append({
                "file": result.file_path,
                "line": result.line_number,
                "pattern": result.pattern_name,
                "severity": result.severity,
                "message": result.message,
                "suggested_fix": result.suggested_fix
            })
        
        return json.dumps(report_data, indent=2)
    
    def _generate_markdown_report(self, results: List[DetectionResult]) -> str:
        """Generate Markdown report for documentation"""
        
        if not results:
            return "## ‚úÖ Hardcoded Rules Scan Results\n\nNo hardcoded rules detected!"
        
        report = []
        report.append("## üö® Hardcoded Rules Detection Report")
        report.append(f"**Total Violations**: {len(results)}")
        report.append(f"**Files Scanned**: {self.stats['files_scanned']}")
        report.append("")
        
        # Group results by file
        by_file = {}
        for result in results:
            by_file.setdefault(result.file_path, []).append(result)
        
        for file_path, file_results in by_file.items():
            report.append(f"### üìÑ `{file_path}`")
            report.append("")
            
            for result in file_results:
                severity_emoji = {
                    "CRITICAL": "üî¥",
                    "HIGH": "üü°", 
                    "MEDIUM": "üü†",
                    "LOW": "üü¢"
                }.get(result.severity, "‚ö™")
                
                report.append(f"**Line {result.line_number}** {severity_emoji} {result.severity}")
                report.append(f"- **Issue**: {result.message}")
                report.append(f"- **Fix**: {result.suggested_fix}")
                report.append("")
        
        return "\n".join(report)

def main():
    parser = argparse.ArgumentParser(description="Vector Wave Hardcoded Rule Detector")
    parser.add_argument("path", nargs="?", default=".", help="Path to scan")
    parser.add_argument("--format", choices=["console", "json", "markdown"], 
                       default="console", help="Output format")
    parser.add_argument("--output", "-o", help="Output file (default: stdout)")
    parser.add_argument("--strict", action="store_true", 
                       help="Exit with error code if violations found")
    parser.add_argument("--config", help="Custom configuration file")
    
    args = parser.parse_args()
    
    # Initialize detector
    detector = HardcodedRuleDetector(args.config)
    
    # Scan directory
    scan_path = Path(args.path)
    if not scan_path.exists():
        print(f"Error: Path {scan_path} does not exist", file=sys.stderr)
        sys.exit(1)
    
    print(f"üîç Scanning {scan_path} for hardcoded rules...")
    results = detector.scan_directory(scan_path)
    
    # Generate report
    report = detector.generate_report(results, args.format)
    
    # Output report
    if args.output:
        with open(args.output, 'w') as f:
            f.write(report)
        print(f"Report saved to {args.output}")
    else:
        print(report)
    
    # Exit with appropriate code
    if args.strict and results:
        print(f"\n‚ùå Found {len(results)} hardcoded rule violations", file=sys.stderr)
        sys.exit(1)
    
    if results:
        print(f"\n‚ö†Ô∏è  Found {len(results)} hardcoded rule violations")
        sys.exit(0)  # Warning but no error in non-strict mode
    else:
        print("\n‚úÖ No hardcoded rules found!")
        sys.exit(0)

if __name__ == "__main__":
    main()
```

### 2.2 Usage Examples

```bash
# Basic scan of current directory
python hardcoded_detector.py

# Scan specific directory with JSON output
python hardcoded_detector.py /path/to/vector-wave --format json --output scan-results.json

# Strict mode for CI/CD (fails if violations found)
python hardcoded_detector.py . --strict

# Generate Markdown report for documentation
python hardcoded_detector.py . --format markdown --output HARDCODED_RULES_SCAN.md
```

---

## ü™ù 3. PRE-COMMIT HOOK INTEGRATION

### 3.1 Git Pre-commit Hook

```bash
#!/bin/bash
# .git/hooks/pre-commit
# Vector Wave Hardcoded Rule Prevention

echo "üîç Vector Wave: Scanning for hardcoded rules..."

# Run hardcoded rule detector
python tools/hardcoded_detector.py . --format json --output /tmp/hardcoded_scan.json --strict

exit_code=$?

if [ $exit_code -ne 0 ]; then
    echo ""
    echo "‚ùå COMMIT BLOCKED: Hardcoded rules detected!"
    echo ""
    echo "üìã Quick fixes:"
    echo "  ‚Ä¢ Replace hardcoded arrays with ChromaDB queries"
    echo "  ‚Ä¢ Use Editorial Service API endpoints" 
    echo "  ‚Ä¢ Move test data to test files"
    echo ""
    echo "üìñ See: target-version/ENHANCED_MOCK_DETECTION_STRATEGY.md"
    echo ""
    exit 1
fi

echo "‚úÖ No hardcoded rules detected - commit allowed"
exit 0
```

### 3.2 Pre-commit Framework Integration

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: vector-wave-hardcoded-detector
        name: Vector Wave Hardcoded Rule Detector
        entry: python tools/hardcoded_detector.py
        language: python
        args: ['.', '--strict']
        files: \.(py|js|ts|yaml|yml|json)$
        exclude: ^(tests/|test_|_test\.py|conftest\.py|node_modules/)
        
  - repo: local
    hooks:
      - id: chromadb-source-validation
        name: Validate ChromaDB Rule Sources
        entry: python tools/validate_chromadb_sources.py
        language: python
        args: ['--verify-origin']
        pass_filenames: false
```

---

## üè≠ 4. CI/CD PIPELINE INTEGRATION

### 4.1 GitHub Actions Workflow

```yaml
# .github/workflows/hardcoded-rule-detection.yml
name: Hardcoded Rule Detection

on:
  pull_request:
    branches: [main, develop]
  push:
    branches: [main, develop]

jobs:
  detect-hardcoded-rules:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Full history for better detection
        
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        
    - name: Run Hardcoded Rule Detection
      id: detection
      run: |
        python tools/hardcoded_detector.py . --format json --output hardcoded-scan-results.json
        
    - name: Upload Scan Results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: hardcoded-rule-scan-results
        path: hardcoded-scan-results.json
        
    - name: Generate PR Comment
      if: github.event_name == 'pull_request'
      run: |
        python tools/generate_pr_comment.py hardcoded-scan-results.json > pr-comment.md
        
    - name: Comment PR
      if: github.event_name == 'pull_request' && failure()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const comment = fs.readFileSync('pr-comment.md', 'utf8');
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  validate-chromadb-integration:
    runs-on: ubuntu-latest
    needs: detect-hardcoded-rules
    
    steps:
    - uses: actions/checkout@v3
      
    - name: Start ChromaDB
      run: |
        docker run -d -p 8000:8000 chromadb/chroma:latest
        sleep 10
        
    - name: Validate Zero Hardcoded Rules
      run: |
        python tools/validate_zero_hardcoded_rules.py --chromadb-url http://localhost:8000
        
    - name: Test Editorial Service Integration
      run: |
        python tools/test_editorial_service_integration.py
```

### 4.2 Pipeline Failure Handling

```python
# tools/generate_pr_comment.py
"""Generate PR comment for hardcoded rule violations"""

import json
import sys
from pathlib import Path

def generate_pr_comment(scan_results_path: str) -> str:
    """Generate PR comment from scan results"""
    
    with open(scan_results_path) as f:
        results = json.load(f)
    
    if results["summary"]["total_violations"] == 0:
        return "‚úÖ **Hardcoded Rule Scan**: No violations detected!"
    
    comment = []
    comment.append("## üö® Hardcoded Rules Detected")
    comment.append("")
    comment.append(f"**Total Violations**: {results['summary']['total_violations']}")
    comment.append("")
    
    # Severity breakdown
    comment.append("### üìä Severity Breakdown")
    for severity, count in results["summary"]["severity_breakdown"].items():
        emoji = {"CRITICAL": "üî¥", "HIGH": "üü°", "MEDIUM": "üü†", "LOW": "üü¢"}.get(severity, "‚ö™")
        comment.append(f"- {emoji} **{severity}**: {count}")
    comment.append("")
    
    # Top violations
    comment.append("### üîç Key Violations")
    
    critical_violations = [v for v in results["violations"] if v["severity"] == "CRITICAL"]
    for violation in critical_violations[:5]:  # Show top 5
        comment.append(f"**üìÑ `{violation['file']}:{violation['line']}`**")
        comment.append(f"- {violation['message']}")
        comment.append(f"- üí° **Fix**: {violation['suggested_fix']}")
        comment.append("")
    
    comment.append("### üìñ How to Fix")
    comment.append("1. Review the [Enhanced Mock Detection Strategy](./target-version/ENHANCED_MOCK_DETECTION_STRATEGY.md)")
    comment.append("2. Replace hardcoded rules with ChromaDB queries via Editorial Service API")
    comment.append("3. Use `python tools/hardcoded_detector.py . --format console` for detailed guidance")
    comment.append("4. See [ChromaDB Schema Specification](./target-version/CHROMADB_SCHEMA_SPECIFICATION.md) for proper data structure")
    
    return "\n".join(comment)

if __name__ == "__main__":
    if len(sys.argv) != 2:
        print("Usage: python generate_pr_comment.py <scan_results.json>")
        sys.exit(1)
    
    comment = generate_pr_comment(sys.argv[1])
    print(comment)
```

---

## üß™ 5. RUNTIME VALIDATION SYSTEM

### 5.1 Editorial Service Health Checks

```python
# Runtime validation for zero hardcoded rules
class HardcodedRuleRuntimeValidator:
    """Runtime validation to ensure no hardcoded rules in production"""
    
    def __init__(self, editorial_service_url: str):
        self.editorial_service_url = editorial_service_url
        self.validation_cache = {}
        
    async def validate_rule_sources(self) -> Dict[str, Any]:
        """Validate all rules come from ChromaDB"""
        
        # Get cache dump from Editorial Service
        async with httpx.AsyncClient() as client:
            response = await client.get(f"{self.editorial_service_url}/cache/dump")
            cache_data = response.json()
        
        # Check each rule has ChromaDB metadata
        violations = []
        total_rules = len(cache_data)
        chromadb_sourced = 0
        
        for rule_id, rule_data in cache_data.items():
            if not rule_data.get("chromadb_metadata"):
                violations.append({
                    "rule_id": rule_id,
                    "issue": "Missing ChromaDB metadata",
                    "severity": "CRITICAL"
                })
            else:
                chromadb_sourced += 1
        
        return {
            "total_rules": total_rules,
            "chromadb_sourced": chromadb_sourced,
            "chromadb_percentage": (chromadb_sourced / total_rules * 100) if total_rules > 0 else 0,
            "violations": violations,
            "status": "HEALTHY" if len(violations) == 0 else "UNHEALTHY"
        }
    
    async def validate_no_hardcoded_fallbacks(self) -> Dict[str, Any]:
        """Check for hardcoded fallback mechanisms"""
        
        # Test circuit breaker behavior
        # Temporarily disable ChromaDB connection and verify graceful degradation
        validation_results = []
        
        try:
            # Test with invalid ChromaDB connection
            async with httpx.AsyncClient() as client:
                response = await client.post(
                    f"{self.editorial_service_url}/validate/comprehensive",
                    json={
                        "content": "test content",
                        "platform": "linkedin",
                        "force_chromadb_error": True  # Test endpoint
                    }
                )
                
                if response.status_code == 200:
                    result = response.json()
                    
                    if result.get("fallback_used"):
                        validation_results.append({
                            "issue": "Hardcoded fallback detected",
                            "details": result.get("fallback_source", "unknown"),
                            "severity": "CRITICAL"
                        })
                    elif result.get("circuit_breaker_triggered"):
                        # This is expected behavior
                        validation_results.append({
                            "issue": "Circuit breaker working correctly",
                            "severity": "INFO"
                        })
        
        except Exception as e:
            validation_results.append({
                "issue": f"Circuit breaker test failed: {str(e)}",
                "severity": "HIGH"
            })
        
        return {
            "circuit_breaker_tests": validation_results,
            "status": "HEALTHY" if all(v["severity"] in ["INFO", "LOW"] for v in validation_results) else "UNHEALTHY"
        }

# Health check endpoint integration
@app.get("/health/hardcoded-rules")
async def health_check_hardcoded_rules():
    """Health check specifically for hardcoded rule validation"""
    
    validator = HardcodedRuleRuntimeValidator("http://localhost:8040")
    
    rule_source_check = await validator.validate_rule_sources()
    fallback_check = await validator.validate_no_hardcoded_fallbacks()
    
    overall_status = (
        "HEALTHY" if 
        rule_source_check["status"] == "HEALTHY" and 
        fallback_check["status"] == "HEALTHY" 
        else "UNHEALTHY"
    )
    
    return {
        "status": overall_status,
        "timestamp": datetime.now().isoformat(),
        "checks": {
            "rule_sources": rule_source_check,
            "circuit_breaker": fallback_check
        },
        "summary": {
            "total_violations": len(rule_source_check["violations"]) + 
                              len([v for v in fallback_check["circuit_breaker_tests"] 
                                   if v["severity"] in ["CRITICAL", "HIGH"]]),
            "chromadb_percentage": rule_source_check["chromadb_percentage"]
        }
    }
```

### 5.2 Continuous Monitoring

```python
# Continuous monitoring script
class HardcodedRuleMonitor:
    """Continuous monitoring for hardcoded rules in production"""
    
    def __init__(self):
        self.alert_thresholds = {
            "chromadb_percentage_min": 100.0,  # Must be 100%
            "violation_count_max": 0,  # Zero tolerance
            "circuit_breaker_failures_max": 0
        }
        self.monitoring_interval = 300  # 5 minutes
        
    async def run_continuous_monitoring(self):
        """Run continuous monitoring loop"""
        
        while True:
            try:
                # Run validation
                async with httpx.AsyncClient() as client:
                    response = await client.get("http://localhost:8040/health/hardcoded-rules")
                    health_data = response.json()
                
                # Check alert conditions
                alerts = self._check_alert_conditions(health_data)
                
                if alerts:
                    await self._send_alerts(alerts)
                
                # Log status
                self._log_monitoring_status(health_data)
                
            except Exception as e:
                await self._send_alerts([{
                    "type": "MONITORING_FAILURE",
                    "message": f"Hardcoded rule monitoring failed: {str(e)}",
                    "severity": "HIGH"
                }])
            
            await asyncio.sleep(self.monitoring_interval)
    
    def _check_alert_conditions(self, health_data: Dict) -> List[Dict]:
        """Check if any alert conditions are met"""
        
        alerts = []
        summary = health_data.get("summary", {})
        
        # ChromaDB percentage check
        chromadb_pct = summary.get("chromadb_percentage", 0)
        if chromadb_pct < self.alert_thresholds["chromadb_percentage_min"]:
            alerts.append({
                "type": "CHROMADB_PERCENTAGE_LOW",
                "message": f"ChromaDB sourced rules: {chromadb_pct}% (expected: 100%)",
                "severity": "CRITICAL",
                "current_value": chromadb_pct,
                "threshold": self.alert_thresholds["chromadb_percentage_min"]
            })
        
        # Violation count check
        violation_count = summary.get("total_violations", 0)
        if violation_count > self.alert_thresholds["violation_count_max"]:
            alerts.append({
                "type": "HARDCODED_VIOLATIONS_DETECTED",
                "message": f"Hardcoded rule violations detected: {violation_count}",
                "severity": "CRITICAL",
                "current_value": violation_count,
                "threshold": self.alert_thresholds["violation_count_max"]
            })
        
        return alerts
    
    async def _send_alerts(self, alerts: List[Dict]):
        """Send alerts via configured channels"""
        
        for alert in alerts:
            # Log alert
            logger.error(f"HARDCODED_RULE_ALERT: {alert['message']}")
            
            # Send Slack notification (if configured)
            if SLACK_WEBHOOK_URL:
                await self._send_slack_alert(alert)
            
            # Send email notification (if configured)
            if EMAIL_ALERTS_ENABLED:
                await self._send_email_alert(alert)
    
    def _log_monitoring_status(self, health_data: Dict):
        """Log monitoring status"""
        
        status = health_data.get("status", "UNKNOWN")
        summary = health_data.get("summary", {})
        
        logger.info(f"Hardcoded rule monitoring: {status} - "
                   f"ChromaDB: {summary.get('chromadb_percentage', 0)}%, "
                   f"Violations: {summary.get('total_violations', 0)}")
```

---

## üìã 6. IMPLEMENTATION CHECKLIST

### 6.1 Phase 1: Detection Tool Setup (Week 1)

- [ ] **Create hardcoded_detector.py script**
  - [ ] Implement pattern matching engine
  - [ ] Add context-aware detection
  - [ ] Create multiple output formats (console, JSON, Markdown)
  - [ ] Add file-type specific rules
  - [ ] Test with existing Vector Wave codebase

- [ ] **Setup pre-commit hooks**
  - [ ] Create .git/hooks/pre-commit script
  - [ ] Configure .pre-commit-config.yaml
  - [ ] Test hook integration with sample violations
  - [ ] Document hook installation process

- [ ] **CI/CD Integration**
  - [ ] Create GitHub Actions workflow
  - [ ] Setup artifact upload for scan results
  - [ ] Configure PR comment generation
  - [ ] Test pipeline with sample pull request

### 6.2 Phase 2: Runtime Validation (Week 2)

- [ ] **Editorial Service Integration**
  - [ ] Add /health/hardcoded-rules endpoint
  - [ ] Implement cache source validation
  - [ ] Add circuit breaker testing
  - [ ] Create ChromaDB metadata verification

- [ ] **Continuous Monitoring**
  - [ ] Deploy monitoring service
  - [ ] Configure alert thresholds
  - [ ] Setup Slack/email notifications
  - [ ] Create monitoring dashboard

### 6.3 Phase 3: Documentation & Training (Week 3)

- [ ] **Documentation**
  - [ ] Complete this strategy document
  - [ ] Create developer quick-start guide
  - [ ] Document common violation fixes
  - [ ] Add troubleshooting guide

- [ ] **Team Training**
  - [ ] Conduct team workshop on detection tools
  - [ ] Create video walkthrough
  - [ ] Establish violation response procedures
  - [ ] Document escalation process

---

## ‚úÖ SUCCESS VALIDATION

### Validation Commands

```bash
# 1. Run full detection scan
python tools/hardcoded_detector.py . --format console
# Expected: "‚úÖ No hardcoded rules detected!"

# 2. Verify Editorial Service health
curl http://localhost:8040/health/hardcoded-rules | jq '.status'
# Expected: "HEALTHY"

# 3. Check ChromaDB source percentage
curl http://localhost:8040/health/hardcoded-rules | jq '.summary.chromadb_percentage'
# Expected: 100.0

# 4. Test pre-commit hook
echo "forbidden_phrases = ['test']" > test_violation.py
git add test_violation.py
git commit -m "test"
# Expected: Commit blocked with violation message

# 5. Validate CI/CD integration
# Create PR with hardcoded rule ‚Üí Should fail with detailed comment
```

### Success Criteria

‚úÖ **Zero False Positives**: Detection accuracy > 99%  
‚úÖ **Complete Coverage**: All file types and patterns covered  
‚úÖ **Fast Execution**: Detection completes in < 30 seconds  
‚úÖ **Developer Experience**: Clear fix suggestions provided  
‚úÖ **CI/CD Integration**: Automated pipeline enforcement  
‚úÖ **Runtime Monitoring**: 24/7 violation detection  
‚úÖ **Team Adoption**: 100% developer hook compliance  

---

**Status**: üìã **Implementation Ready**  
**Timeline**: 3 weeks total implementation  
**Risk Level**: LOW (comprehensive testing strategy)  
**Dependencies**: Editorial Service (Phase 1), ChromaDB integration  

**Next Steps**: Proceed with Phase 1 implementation and link to main migration roadmap.