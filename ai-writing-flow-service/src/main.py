"""
AI Writing Flow Service
FastAPI application providing content generation through CrewAI agents
"""

import os
import time
import logging
from typing import Dict, Any, Optional
from datetime import datetime

from fastapi import FastAPI, HTTPException, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import httpx
from tenacity import retry, stop_after_attempt, wait_exponential

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize FastAPI app
app = FastAPI(
    title="AI Writing Flow Service",
    description="Content generation pipeline using CrewAI agents",
    version="1.0.0"
)

# Configuration
EDITORIAL_SERVICE_URL = os.getenv("EDITORIAL_SERVICE_URL", "http://editorial-service:8040")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")

# Health status tracking
service_health = {
    "status": "starting",
    "last_check": None,
    "dependencies": {}
}


class ContentRequest(BaseModel):
    """Request model for content generation"""
    content: str = Field(..., description="Content to process")
    platform: str = Field(default="general", description="Target platform")
    topic: Optional[Dict[str, Any]] = Field(default=None, description="Topic metadata")
    validation_mode: str = Field(default="selective", description="Validation mode")
    
class GenerateRequest(BaseModel):
    """Request model for full content generation"""
    topic_title: str = Field(..., description="Topic title")
    topic_description: str = Field(..., description="Topic description")
    platform: str = Field(default="linkedin", description="Target platform")
    viral_score: float = Field(default=7.5, description="Viral potential score")
    
class ContentResponse(BaseModel):
    """Response model for generated content"""
    content: str
    metadata: Dict[str, Any]
    processing_time: float
    agents_used: list
    

@app.on_event("startup")
async def startup_event():
    """Initialize service on startup"""
    logger.info("AI Writing Flow Service starting...")
    service_health["status"] = "healthy"
    service_health["last_check"] = datetime.utcnow().isoformat()
    

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    # Check Editorial Service connectivity
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                f"{EDITORIAL_SERVICE_URL}/health",
                timeout=5.0
            )
            editorial_healthy = response.status_code == 200
    except Exception as e:
        logger.warning(f"Editorial Service health check failed: {e}")
        editorial_healthy = False
    
    service_health["dependencies"]["editorial_service"] = editorial_healthy
    service_health["last_check"] = datetime.utcnow().isoformat()
    
    # Overall health status
    if not editorial_healthy:
        service_health["status"] = "degraded"
    else:
        service_health["status"] = "healthy"
    
    status_code = 200 if service_health["status"] == "healthy" else 503
    
    return JSONResponse(
        content={
            "status": service_health["status"],
            "timestamp": service_health["last_check"],
            "dependencies": service_health["dependencies"],
            "version": "1.0.0"
        },
        status_code=status_code
    )
    

@app.post("/generate", response_model=ContentResponse)
async def generate_content(request: GenerateRequest):
    """Generate content using AI Writing Flow pipeline"""
    start_time = time.time()
    
    try:
        # Simulate agent pipeline execution
        agents_used = ["research", "audience", "writer", "style", "quality"]
        
        # Create initial content structure
        content = f"""# {request.topic_title}

{request.topic_description}

## Key Points

Based on comprehensive research and audience analysis, here are the main insights:

1. **Market Relevance**: This topic has high engagement potential with a viral score of {request.viral_score}/10.

2. **Target Audience**: Professionals and enthusiasts interested in cutting-edge developments.

3. **Content Strategy**: Optimized for {request.platform} platform engagement patterns.

## Deep Dive

{request.topic_description}

This content explores the nuances and implications of the topic, providing actionable insights and thought leadership perspectives that resonate with our target audience.

## Conclusion

The analysis reveals significant opportunities for engagement and value creation in this domain.

---
*Generated by AI Writing Flow | Platform: {request.platform}*"""
        
        # Call Editorial Service for validation (selective mode by default)
        validation_result = await validate_with_editorial(content, request.platform)
        
        # Apply suggestions if any
        if validation_result and validation_result.get("suggestions"):
            logger.info(f"Applying {len(validation_result['suggestions'])} suggestions")
            # In production, we would apply these suggestions to improve content
        
        processing_time = time.time() - start_time
        
        return ContentResponse(
            content=content,
            metadata={
                "topic_title": request.topic_title,
                "platform": request.platform,
                "viral_score": request.viral_score,
                "validation_applied": bool(validation_result)
            },
            processing_time=processing_time,
            agents_used=agents_used
        )
        
    except Exception as e:
        logger.error(f"Content generation failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/process", response_model=ContentResponse)
async def process_content(request: ContentRequest):
    """Process existing content through AI Writing Flow pipeline"""
    start_time = time.time()
    
    try:
        # Determine which agents to use based on validation mode
        if request.validation_mode == "comprehensive":
            agents_used = ["research", "audience", "writer", "style", "quality"]
        else:  # selective
            agents_used = ["writer", "style"]
        
        # Process content through selected agents
        processed_content = request.content
        
        # Simulate agent processing
        for agent in agents_used:
            logger.info(f"Processing with agent: {agent}")
            # In production, each agent would modify the content
            processed_content = f"{processed_content}\n\n/* Processed by {agent} agent */"
        
        # Validate with Editorial Service
        validation_result = await validate_with_editorial(
            processed_content, 
            request.platform,
            request.validation_mode
        )
        
        processing_time = time.time() - start_time
        
        return ContentResponse(
            content=processed_content,
            metadata={
                "original_length": len(request.content),
                "processed_length": len(processed_content),
                "platform": request.platform,
                "validation_mode": request.validation_mode,
                "validation_result": validation_result
            },
            processing_time=processing_time,
            agents_used=agents_used
        )
        
    except Exception as e:
        logger.error(f"Content processing failed: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=10))
async def validate_with_editorial(
    content: str, 
    platform: str,
    validation_mode: str = "selective"
) -> Optional[Dict[str, Any]]:
    """Validate content with Editorial Service"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                f"{EDITORIAL_SERVICE_URL}/validate/{validation_mode}",
                json={
                    "content": content,
                    "platform": platform
                },
                timeout=30.0
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                logger.warning(f"Editorial validation returned {response.status_code}")
                return None
                
    except Exception as e:
        logger.error(f"Editorial Service validation failed: {e}")
        return None


@app.get("/")
async def root():
    """Root endpoint with service information"""
    return {
        "service": "AI Writing Flow",
        "version": "1.0.0",
        "status": service_health["status"],
        "endpoints": [
            "/health",
            "/generate",
            "/process",
            "/docs"
        ]
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)